{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import laspy as lp\n",
    "import numpy as np\n",
    "import scipy\n",
    "from laspy.file import File\n",
    "from scipy.spatial.kdtree import KDTree\n",
    "import torch \n",
    "import pickle\n",
    "import time as time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from numpy.random import (normal,uniform)\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "from matplotlib.patches import Circle\n",
    "from glob import glob\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cluster():\n",
    "    def __init__(self, points):\n",
    "        self.points = np.array(points)\n",
    "        print(self.points.shape)\n",
    "        self.roughness = np.nanstd(self.points[:,-1])\n",
    "\n",
    "    def boundpoints(self):\n",
    "        x_min = np.min(self.points[:,0])\n",
    "        x_max = np.max(self.points[:,0])\n",
    "        y_min = np.min(self.points[:,1])\n",
    "        y_max = np.max(self.points[:,1])\n",
    "        return np.array([[x_min,x_max],[y_min,y_max]])\n",
    "\n",
    "\n",
    "class scan(cluster):\n",
    "    def __init__(self,filepath):\n",
    "        start = time.time()\n",
    "        self.file = File(filepath,mode=\"r\")\n",
    "        self.scale = self.file.header.scale[0]\n",
    "        self.offset = self.file.header.offset[0]\n",
    "        self.tree = KDTree(np.vstack([self.file.x, self.file.y, self.file.z]).transpose())\n",
    "        self.time = self.file.header.get_date()\n",
    "        end = time.time() - start\n",
    "        print(\"Time Elapsed: {}\".format(end))\n",
    "\n",
    "    def nearNeighbor(self,point,k=1):\n",
    "        return self.tree.query(point,k=k)\n",
    "\n",
    "    def radialcluster(self,point,radius):\n",
    "        neighbor = self.tree.data[self.tree.query(point,k=1)[1]]\n",
    "        points = self.tree.data[self.tree.query_ball_point(neighbor,radius)]\n",
    "        print(\"{} Points \\n\".format(points.shape[0]))\n",
    "        return np.array(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "1) Generate a set of clusters in an observer class with a time stamp\n",
    "\n",
    "2) Generate hypothesis points according to a normal distribution\n",
    "\n",
    "3) Weight each hypothesis point with F(Hypthesis, Cluster) function\n",
    "\n",
    "4) Resample \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class particle_set():  \n",
    "    \n",
    "    def __init__(points,center,weight=None):\n",
    "        self.points = points\n",
    "        self.center = center\n",
    "        self.weight = weight\n",
    "        \n",
    "    def set_weight(self,weight):\n",
    "        self.weight = weight\n",
    "        \n",
    "\n",
    "class observer(particle_set):\n",
    "    def __init__(self,obs):\n",
    "        self.observations = obs\n",
    "        self.observations.sort(key= lambda scan: scan.time)\n",
    "        self.particles = None\n",
    "        \n",
    "        \n",
    "    def particle_centroid(self,mean, std, N):\n",
    "        particles = np.empty((N, 3))\n",
    "        particles[:, 0] = normal(mean[0],std[0],N) # x pos\n",
    "        particles[:, 1] = normal(mean[1],std[1],N) # y pos\n",
    "        particles[:, 3] = normal(mean[2],std[2],N)\n",
    "        return particles\n",
    "    \n",
    "    def particle_clusters(self,particles,observer_index):\n",
    "        particle_set = []\n",
    "        for i in range(particles.shape[0]):\n",
    "            points = self.observations[observer_index].radialcluster(particles[i,:,:],10)\n",
    "            cluster = particle_set(points,particles[i,:,:])\n",
    "            particle_set.append(cluster)\n",
    "        return particle_set\n",
    "    \n",
    "    def gen_particles(self,mean,std,N,obs_indx):\n",
    "        particles = self.particle_centroid(mean,STD,N)\n",
    "        self.particles = self.particle_clusters(particles,obs_indx)\n",
    "        return self.particles\n",
    "        \n",
    "    ###################\n",
    "    def kernel(self,x):\n",
    "        return ((1/(2*np.pi))^3)*np.exp(-(x/2))\n",
    "        \n",
    "    def d_sigma(self,X,Y):\n",
    "        m = X.shape[0]\n",
    "        n = Y.shape[0]\n",
    "        mat = np.zeros((m,n))\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                mat[i,j] = X[i,:] - Y[j,:]\n",
    "        H = np.linalg.inv(mat@mat.T)\n",
    "        return np.sqrt(mat.T@H@mat)\n",
    "    \n",
    "    def bandwidth(self,X):\n",
    "        return np.min(self.d_sigma(X,X))\n",
    "    \n",
    "    def reach_distance(self,X,Y):\n",
    "        A = self.d_sigma(X,Y)\n",
    "        B = self.d_sigma(Y,Y)\n",
    "        if np.sum(A) > np.sum(B):\n",
    "            return A\n",
    "        else:\n",
    "            return B\n",
    "        \n",
    "        \n",
    "    def evaluate(self,X,Y):\n",
    "        # X is hypothesis\n",
    "        # Y is reference\n",
    "        A = self.reach_distance(X,Y)\n",
    "        B = self.bandwidth(Y)\n",
    "        C = (1/(B^3))*self.kernel(A/B)\n",
    "        return(np.mean(C))\n",
    "       \n",
    "    def weight_cluster(self,X,Y):\n",
    "        # assign a cluster weight given a reference cluster\n",
    "        # X is hypothesis\n",
    "        # Y is reference\n",
    "        weight = self.evaluate(X,Y)\n",
    "        X.set_weight(weight)\n",
    "    \n",
    "    def resample(self,particle_set):\n",
    "        weights = np.array([points.weights for points in particle_set])\n",
    "        cumsum = np.cumsum(weights)\n",
    "        indexes = np.searchsorted(cumsum,uniform(0,1,np.max(weights.shape)))\n",
    "        for i, particle in enumerate(particle_set):\n",
    "            particle.weights = particle_set[indexes[i]].weights\n",
    "            \n",
    "    ####################################\n",
    "    def update(self,particle_set,vels):\n",
    "        for i, _ in enumerate(particle_set):\n",
    "            for j,_ in enumerate(particles.points):\n",
    "                particle_set[i].points[j,:] += vels\n",
    "            \n",
    "        \n",
    "    def estimate(self,particle_set):\n",
    "        positions = [cluster.center for cluster in particles]\n",
    "        weights = [particle.weight for particle in particle_set]\n",
    "        mean = np.average(positions,weights=weights)\n",
    "        var = np.var(positions,weights=weights)\n",
    "        return mean, np.linalg.norm(var)  #returns the estimated location\n",
    "    \n",
    "    def predict(self,point,guess,ref_index,test_index):\n",
    "        ref_cluster = self.observations[ref_index].radialcluster(point,10)\n",
    "        hypothesis = self.gen_particles(guess,10,1000,test_index)\n",
    "        self.weight_cluster(hypothesis,ref_cluster)\n",
    "        self.resample(hypothesis)\n",
    "        return self.estimate(hypothesis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 117.76095771789551\n",
      "Time Elapsed: 112.37241721153259\n",
      "Time Elapsed: 107.26848673820496\n",
      "Time Elapsed: 127.11175918579102\n",
      "Time Elapsed: 116.3790545463562\n"
     ]
    }
   ],
   "source": [
    "files = glob(join(\"/home/dunbar/Research/helheim/data/misc/lazfiles\",\"*.laz\"))\n",
    "scans = [scan(file) for file in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observer = observer(scans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    dt = np.array([10,5,1])\n",
    "    point += dt\n",
    "    return point\n",
    "start = np.array([534330.24,7361293.11,175])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(observer.obervations)-1):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
